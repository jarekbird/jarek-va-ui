# TASK-4: Set up the testing framework (test runner config, `setupTests.ts`, jsdom environment, etc.).

**Section**: 0. Repo & Environment Setup
**Subsection**: 0.X
**Task ID**: TASK-4

## Description

4. Set up the testing framework (test runner config, `setupTests.ts`, jsdom environment, etc.).

This task is part of the migration plan to build `cursor-executor-front`, a new React + TypeScript application that will host conversation and task views migrated from the legacy UI. The application will use TanStack Query for server state management and TanStack Router (or React Router) for routing.

**IMPORTANT: Implementation Location**

All changes for this task must be made in the `cursor-executor-front` application located at `python-cursor/cursor-executor/cursor-executor-front/`. Do not make changes in the `jarek-va-ui` application.

## Current State

- TypeScript is configured (from task 3)
- Testing framework needs to be set up (Vitest recommended based on existing setup)
- Need to configure test runner, setupTests.ts, and jsdom environment
- Testing libraries are installed but not configured

## Checklist

### Preparation and Setup

- [ ] Review relevant documentation and reference implementations
- [ ] Understand dependencies and prerequisites (tasks 1-3 should be completed)
- [ ] Review API documentation from task 9 (if applicable)
- [ ] Review related tasks and their status
- [ ] Identify any blockers or risks

### Implementation Steps

- [ ] Step 1: Configure Vitest
  - [ ] Create `vitest.config.ts` in project root
  - [ ] Set `test.environment = 'jsdom'` for DOM testing
  - [ ] Configure test file patterns: `include: ['**/*.{test,spec}.{ts,tsx}']`
  - [ ] Set up coverage configuration if needed
  - [ ] Configure path aliases to match tsconfig.json
- [ ] Step 2: Create setupTests.ts
  - [ ] Create `src/setupTests.ts` or `src/test/setup.ts`
  - [ ] Import `@testing-library/jest-dom` for custom matchers
  - [ ] Configure any global test utilities or mocks
  - [ ] Update vitest.config.ts to reference setup file: `setupFiles: ['./src/setupTests.ts']`
- [ ] Step 3: Configure test cleanup to prevent hanging
  - [ ] Create `src/test/setup.ts` or `src/test/setup/cleanup.ts` for test cleanup utilities
  - [ ] Set up global teardown hooks in Vitest config to ensure all resources are cleaned up
  - [ ] Configure `afterEach` hooks to clean up any timers, event listeners, or async operations
  - [ ] Ensure QueryClient instances are properly cleaned up after tests
  - [ ] Add cleanup for any mock servers, WebSocket connections, or other persistent resources
- [ ] Step 4: Verify test setup
  - [ ] Create a simple test file: `src/App.test.tsx` with basic test
  - [ ] Run `npm test -- --run` to ensure tests can execute (use `--run` flag, never pipe output)
  - [ ] Verify jsdom environment is working
  - [ ] Verify test matchers from jest-dom are available
  - [ ] Verify tests complete without hanging (no open handles warnings)

### Specific Requirements

- [ ] All tests must pass
- [ ] Test coverage should meet project standards
- [ ] Tests should be maintainable and well-documented
- [ ] Tests should use appropriate testing patterns (arrange-act-assert)
- [ ] **CRITICAL: Test cleanup must be implemented to prevent hanging**
  - [ ] All timers (setTimeout, setInterval) must be cleared after tests
  - [ ] All QueryClient instances must be cleaned up
  - [ ] All event listeners must be removed
  - [ ] All mock servers or network mocks must be closed
  - [ ] Tests must not leave any open handles or async operations running
  - [ ] Use Vitest's `afterEach` and `afterAll` hooks for cleanup
  - [ ] Configure global teardown if needed for shared resources

### Error Handling and Edge Cases

- [ ] Handle network errors gracefully
- [ ] Handle missing or invalid data
- [ ] Handle edge cases specific to this task
- [ ] Provide meaningful error messages
- [ ] Handle loading states appropriately
- [ ] Handle empty states where applicable

### Testing

- [ ] Write unit tests for new functionality
- [ ] Write integration tests if applicable
- [ ] Test error handling paths
- [ ] Test edge cases
- [ ] **CRITICAL: Safe Test Execution**
  - [ ] **NEVER pipe test output** (e.g., `npm test | head` will cause deadlocks)
  - [ ] For Vitest, use: `npm run test -- --run --reporter=json --outputFile=/tmp/vitest-results.json`
  - [ ] Then read and display results from the JSON file (see Software Developer instructions)
  - [ ] Always use `--run` flag for single execution (not watch mode)
- [ ] Run full test suite: `npm test -- --run` (never pipe output)
- [ ] Run type checking: `npm run type-check` (if applicable)
- [ ] Run linting: `npm run lint` (if applicable)
- [ ] Verify test coverage: `npm run test:coverage` (if applicable)
- [ ] **DO NOT manually test by running the server** - use automated tests instead
- [ ] Ensure all affected functionality is covered by automated tests
- [ ] **Verify no open handles**: Tests must complete without warnings about open handles or async operations

### Documentation

- [ ] Update code comments and JSDoc/TSDoc as needed
- [ ] Update relevant documentation files
- [ ] Document any breaking changes (if applicable)
- [ ] Update architecture documentation if structural changes were made
- [ ] Document any patterns or conventions established

### Verification

- [ ] Verify all requirements are met
- [ ] Verify no regressions were introduced
- [ ] Verify code quality standards are met
- [ ] Review code for best practices
- [ ] Ensure proper error handling is in place
- [ ] Verify performance considerations (if applicable)

## Notes

- This task is part of Section 0: Repo & Environment Setup
- **Execution Timing**: This task should be executed after completing tasks 1-3
- **Dependencies**: 
  - Tasks 1, 2, 3 must be completed first
- **Important Considerations**: 
  - Follow the patterns established in the existing jarek-va-ui application where applicable
  - Ensure consistency with the overall architecture plan
  - Consider future tasks when making design decisions
  - Reference the master-plan.md for overall context
  - **CRITICAL: Test Cleanup Requirements**
    - This is the first task where testing infrastructure is established
    - All future tests must follow the cleanup patterns established here
    - See Software Developer instructions for detailed cleanup requirements:
      - Always terminate Node processes, HTTP servers, Redis connections, databases
      - Always clear timers and event listeners
      - Always clean up QueryClient instances
      - Never leave async operations running after tests complete
      - Use global teardown hooks and `afterEach`/`afterAll` for cleanup
      - Fail tests if Vitest reports open handles or unfinished async operations
- **Task Independence**: This task can be completed independently once dependencies are met
- **Current State**: See "Current State" section above

## Related Tasks

- Previous: TASK-3
- Next: TASK-5
- Dependencies:
  - Tasks 1-3 must be completed first
- Related:
  - All tasks in Section 0: Repo & Environment Setup

## Definition of Done

This task is a **TESTING TASKS** task.

### User Stories

**As a developer**, I want to complete this task so that:
- The functionality described in the task is implemented and working
- The code is well-tested with automated tests
- The implementation follows project standards and best practices
- The changes are committed and pushed to the repository
- Future tasks can build upon this work

**As a user** (for UI-related tasks), I want:
- The feature to work as expected
- The UI to be responsive and accessible
- Error states to be handled gracefully

### Acceptance Criteria

1. **Implementation Complete**
   - All code changes are implemented as specified in the task description
   - Code follows project conventions and style guide
   - All functionality works as expected
   - Code is properly typed with TypeScript (no `any` types unless necessary)

2. **Automated Tests**
   - Unit tests are written and passing for all new functionality
   - Integration tests are written where applicable
   - Test coverage meets project requirements (aim for >80% for new code)
   - All tests pass: `npm test` (or equivalent)
   - Type checking passes: `npm run type-check` (if applicable)
   - Linting passes: `npm run lint` (if applicable)
   - No test warnings or errors

3. **Code Quality**
   - Code is reviewed and follows best practices
   - Error handling is implemented appropriately
   - Edge cases are handled
   - No regressions introduced
   - Code is maintainable and well-documented

4. **Documentation**
   - Code is properly commented with JSDoc/TSDoc where helpful
   - Documentation is updated as needed
   - Any breaking changes are documented
   - README or relevant docs are updated if project structure changes

5. **Git Commit and Push**
   - All changes are committed to git with a descriptive commit message
   - Commit message follows project conventions: `TASK-4: Set up the testing framework (test runner config, `setupTests.ts`, jsdom environment, etc.).`
   - Code is pushed to origin: `git push origin <branch-name>`
   - Commit includes all relevant files (source code, tests, documentation, config)
   - Commit is atomic (all related changes together)

### Final Verification

Before marking this task as complete, verify:
- [ ] All automated tests pass (`npm test`)
- [ ] Type checking passes (`npm run type-check`)
- [ ] Linting passes (`npm run lint`)
- [ ] Code is committed to git with descriptive message
- [ ] Code is pushed to origin
- [ ] Commit message follows conventions
- [ ] All acceptance criteria are met
- [ ] No blocking issues remain

**The task is NOT complete until:**
1. All code is committed to git
2. Code is pushed to origin
3. All tests pass
4. All acceptance criteria are met

**DO NOT mark as complete if:**
- Tests are failing
- Code is not committed
- Code is not pushed to origin
- Type errors exist
- Linting errors exist
