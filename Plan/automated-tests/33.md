# TASK-33: Implement core E2E journeys

**Section**: 7. E2E, Accessibility, and Regression Tests (Phase 4)
**Subsection**: 7.2 Core E2E Test Implementation
**Task ID**: TASK-33

## Description

This task implements core end-to-end (E2E) test journeys for the most critical user flows in the application. These tests run in a real browser and verify that the application works correctly from a user's perspective.

The tests will cover:
- Conversation flows (list, create, detail, navigate)
- Agent conversation flows (list, detail, with ElevenLabs enabled)
- Task dashboard (all panels render, refresh, expand tree)
- Working directory (expand/collapse interactions)
- Simple voice flow (connect/disconnect, happy path only)

These E2E tests complement unit and integration tests by verifying the full application works in a real browser environment.

## Current State

- E2E framework should be set up (from TASK-32)
- Application can be built and run
- Core user flows exist in the application
- No E2E tests currently exist

**Reference Implementation**: 
- E2E framework documentation (Playwright or Cypress)
- Existing E2E test patterns (if any)
- Application user flows

**Important**: This task should be executed after TASK-1, TASK-2, TASK-3, TASK-4, TASK-32 are complete (all unit tests, integration tests, and E2E framework setup).

## Checklist

### Preparation and Setup

- [ ] Review E2E framework setup from TASK-32
- [ ] Review application user flows
- [ ] Review application routes and navigation
- [ ] Understand E2E testing best practices
- [ ] Review existing E2E test patterns (if any)

### Implementation Steps

- [ ] Step 1: Create E2E test structure
  - [ ] Create `e2e/conversations.spec.ts` (or `.test.ts` for Playwright)
  - [ ] Create `e2e/agent-conversations.spec.ts`
  - [ ] Create `e2e/task-dashboard.spec.ts`
  - [ ] Create `e2e/working-directory.spec.ts`
  - [ ] Create `e2e/voice.spec.ts`

- [ ] Step 2: Write E2E tests for conversation flows
  - [ ] Test: Visit root, confirm conversation list loads
  - [ ] Test: Conversations are displayed in list
  - [ ] Test: Click conversation to open detail view
  - [ ] Test: Conversation detail displays correctly
  - [ ] Test: Navigate back to list
  - [ ] Test: Create new conversation
  - [ ] Test: New conversation appears in list

- [ ] Step 3: Write E2E tests for agent conversation flows
  - [ ] Test: Visit `/agent-conversations` (with ElevenLabs enabled in env)
  - [ ] Test: Agent conversation list loads
  - [ ] Test: Conversations are displayed
  - [ ] Test: Click conversation to open detail view
  - [ ] Test: Conversation detail displays correctly
  - [ ] Test: Verify data is displayed correctly

- [ ] Step 4: Write E2E tests for task dashboard
  - [ ] Test: Visit `/task-dashboard`
  - [ ] Test: All panels render (file viewer, note-taking, task management, queue view)
  - [ ] Test: Refresh tasks button works
  - [ ] Test: Updated task data is displayed
  - [ ] Test: Expand working directory tree
  - [ ] Test: Tree expands and collapses correctly

- [ ] Step 5: Write E2E tests for working directory
  - [ ] Test: Navigate to view that shows WorkingDirectoryBrowser
  - [ ] Test: File tree is displayed
  - [ ] Test: Click directory to expand
  - [ ] Test: Click directory to collapse
  - [ ] Test: Multiple directories can be expanded
  - [ ] Test: Nested directories work correctly

- [ ] Step 6: Write E2E tests for simple voice flow
  - [ ] Test: With configured backend and agent, select an agent conversation
  - [ ] Test: Click connect button
  - [ ] Test: Verify visible status messages (connected state)
  - [ ] Test: Click disconnect button
  - [ ] Test: Verify visible status messages (disconnected state)
  - [ ] Test: Happy path only (no error scenarios)

### Specific Requirements

- [ ] Requirement 1: Conversation flows tested
  - List loads correctly
  - Detail view works correctly
  - Navigation works correctly
  - Creation works correctly

- [ ] Requirement 2: Agent conversation flows tested
  - List loads correctly
  - Detail view works correctly
  - Data is displayed correctly

- [ ] Requirement 3: Task dashboard tested
  - All panels render
  - Refresh works
  - Tree expand works

- [ ] Requirement 4: Working directory tested
  - Expand/collapse works
  - Multiple directories work
  - Nested directories work

- [ ] Requirement 5: Voice flow tested
  - Connect/disconnect works
  - Status messages are visible
  - Happy path only

### Error Handling and Edge Cases

- [ ] Handle case: App takes time to load
  - Tests wait for app to be ready
  - Timeouts are appropriate

- [ ] Handle case: Network requests are slow
  - Tests wait for content to load
  - Timeouts are appropriate

- [ ] Handle case: Elements not immediately visible
  - Tests wait for elements to appear
  - Proper wait strategies are used

### Testing

- [ ] Write all E2E test cases
- [ ] Use E2E framework best practices
- [ ] Use proper wait strategies
- [ ] Use semantic selectors
- [ ] Run tests: `npm run e2e`
- [ ] Verify all tests pass
- [ ] Run tests in different browsers (if configured)
- [ ] Verify tests are stable (no flakiness)

### Documentation

- [ ] Add JSDoc comments to test files if needed
- [ ] Document test patterns used
- [ ] Add comments for complex test scenarios
- [ ] Document E2E testing approach

### Verification

- [ ] Verify all core E2E journeys are tested
- [ ] Verify tests pass
- [ ] Verify tests are stable
- [ ] Verify no regressions in other tests

## Notes

- This task is part of Section 7: E2E, Accessibility, and Regression Tests (Phase 4)
- **Execution Timing**: Execute after TASK-1, TASK-2, TASK-3, TASK-4, TASK-32 are complete (all unit tests, integration tests, and E2E framework setup)
- **Dependencies**: 
  - TASK-1: Confirm local setup
  - TASK-2: Review existing test utilities
  - TASK-3: Introduce MSW (not needed for E2E - tests run against real app)
  - TASK-4: Configure coverage thresholds
  - TASK-32: Set up Playwright or Cypress for E2E (required)
- **Important Considerations**: 
  - E2E tests run against real application (not mocked)
  - Use proper wait strategies (wait for elements, wait for network, etc.)
  - Use semantic selectors (data-testid, role, text)
  - Keep tests focused on user-visible behavior
  - Test happy paths primarily (error scenarios can be in integration tests)
  - Ensure tests are stable (no flakiness)
- **Task Independence**: Can be completed independently after prerequisites
- **Current State**: E2E framework may be set up but no E2E tests exist

## Related Tasks

- Previous: TASK-32 (Set up Playwright or Cypress for E2E)
- Next: TASK-34 (Add accessibility checks)
- Dependencies:
  - TASK-1: Confirm local setup
  - TASK-2: Review existing test utilities
  - TASK-3: Introduce MSW (not required for E2E)
  - TASK-4: Configure coverage thresholds
  - TASK-32: Set up Playwright or Cypress for E2E (required)
- Related: TASK-32 (E2E framework setup), TASK-34 (accessibility checks)

## Definition of Done

### Task Type: TESTING TASK

**Description**: This task involves writing comprehensive E2E tests for core user journeys.

**Definition of Done**: 

1. **E2E test files created**:
   - `e2e/conversations.spec.ts` exists
   - `e2e/agent-conversations.spec.ts` exists
   - `e2e/task-dashboard.spec.ts` exists
   - `e2e/working-directory.spec.ts` exists
   - `e2e/voice.spec.ts` exists
   - Files follow project conventions and patterns

2. **Tests written**:
   - Conversation flows tested
   - Agent conversation flows tested
   - Task dashboard tested
   - Working directory tested
   - Simple voice flow tested

3. **Tests pass**:
   - All E2E tests pass
   - Tests run successfully: `npm run e2e`
   - No test failures or errors
   - Tests are stable (no flakiness)

4. **Coverage meets requirements**:
   - Core user journeys are covered
   - Critical flows are tested

5. **Code quality**:
   - Tests use semantic selectors
   - Tests use proper wait strategies
   - Tests are readable and maintainable
   - No linting errors
   - Type checking passes

6. **Code committed and pushed**:
   - All E2E test files committed
   - Commit message: `test: implement core E2E journeys for critical user flows`
   - Code pushed to origin: `git push origin <branch-name>`

7. **User Story** (as a developer):
   - **As a** developer maintaining the application
   - **I want** comprehensive E2E tests that verify critical user journeys work correctly in a real browser
   - **So that** I can confidently deploy the application knowing core flows are verified

8. **Automated Tests**:
   - All E2E tests written and passing
   - Tests run successfully: `npm run e2e` must complete successfully
   - Test verification: Run `npm run e2e` and confirm all tests pass

**Acceptance Criteria**:
- ✅ All E2E test files created with comprehensive tests
- ✅ All core user journeys tested (conversations, agent conversations, task dashboard, working directory, voice)
- ✅ All tests pass
- ✅ Tests are stable (no flakiness)
- ✅ All changes committed and pushed to origin

**Tests are written, all tests pass, and test coverage meets project requirements**
