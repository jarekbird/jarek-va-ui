# Integrate Voice Service with AgentConversationDetails UI

## Scope
`jarek-va-ui`.

## Subtasks
- Add voice-mode state and connection state to `AgentConversationDetails.tsx`.
- Add voice controls (Start/Stop, status indicators, mic activity visualization).
- Wire voice session messages into the conversation message list.
- Respect `VITE_ELEVENLABS_AGENT_ENABLED` by hiding controls when disabled.

## Desired Outcomes

### Primary Outcomes
1. **Voice Controls UI**: Intuitive voice controls allowing users to start/stop voice sessions.

2. **Status Indicators**: Clear visual indicators showing connection status and agent mode.

3. **Message Integration**: Voice messages appear in conversation history alongside text messages.

4. **Feature Flag Integration**: Controls hidden when feature is disabled.

5. **User Experience**: Smooth, intuitive voice interaction within the conversation UI.

### Success Criteria
- Voice controls visible and functional
- Status indicators show correct state
- Mic activity visualization works
- Voice messages appear in conversation
- Feature flag properly hides controls
- UI matches design system
- Accessible (keyboard, screen readers)
- Tests cover UI integration

## User Stories

### As a User
- **Story 1**: I want voice controls so that I can easily start and stop voice sessions.
- **Story 2**: I want to see connection status so that I know if voice is working.
- **Story 3**: I want voice messages in conversation history so that I can see what was said.

### As a Developer
- **Story 4**: I want integrated voice UI so that users have a seamless experience.

## Suggested Automated Tests

### Component Tests
1. **Voice Controls Tests**:
   ```typescript
   describe('Voice Controls', () => {
     it('renders start/stop buttons', () => {
       render(<AgentConversationDetails conversation={mockConv} />);
       expect(screen.getByText('Start Voice')).toBeInTheDocument();
     });
     
     it('starts voice session on button click', async () => {
       const mockStart = jest.fn();
       render(<AgentConversationDetails conversation={mockConv} />);
       fireEvent.click(screen.getByText('Start Voice'));
       expect(mockStart).toHaveBeenCalled();
     });
   });
   ```

2. **Status Indicator Tests**:
   ```typescript
   describe('Status Indicators', () => {
     it('shows connection status', () => {
       // Test status display
     });
     
     it('shows agent mode', () => {
       // Test mode indicator
     });
   });
   ```

3. **Feature Flag Tests**:
   ```typescript
   describe('Feature Flag', () => {
     it('hides controls when disabled', () => {
       process.env.VITE_ELEVENLABS_AGENT_ENABLED = 'false';
       render(<AgentConversationDetails conversation={mockConv} />);
       expect(screen.queryByText('Start Voice')).not.toBeInTheDocument();
     });
   });
   ```

## Inherent Risks

### Medium Risk
1. **UI State Management**:
   - **Risk**: Voice state not properly synced with UI, causing inconsistencies
   - **Mitigation**: Proper state management, React hooks, state synchronization

2. **Performance Issues**:
   - **Risk**: Voice UI causing performance problems
   - **Mitigation**: Optimize rendering, use memoization, performance testing

3. **Accessibility Gaps**:
   - **Risk**: Voice controls not accessible to all users
   - **Mitigation**: ARIA labels, keyboard navigation, screen reader testing

### Low Risk
4. **Styling Inconsistencies**:
   - **Risk**: Voice controls don't match design system
   - **Mitigation**: Use design system components, visual QA, style guide

5. **Message Rendering Issues**:
   - **Risk**: Voice messages not rendering correctly
   - **Mitigation**: Test message rendering, handle edge cases, visual QA
