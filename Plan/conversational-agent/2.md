# Verify Current Conversation & Note-Taking Flows

## Scope
`cursor-runner`, `jarek-va-ui`.

## Subtasks
- Trace how `cursor:conversation:{conversationId}` is created and read in `cursor-runner`.
- Confirm `jarek-va-ui` conversation list/detail screens and their dependency on `/conversations/api/*`.
- Capture baseline behavior (screenshots or notes) for regression comparison.
- Add or review minimal automated tests that exercise `/conversations/api/*` list/detail flows so that the current behavior is locked in before renaming.

## Desired Outcomes

### Primary Outcomes
1. **Baseline Understanding**: Complete documentation of how the current conversation/note-taking system works, including:
   - Data flow from cursor-runner to UI
   - Redis key structure and TTL behavior
   - API endpoint contracts and response formats
   - UI component dependencies and data loading patterns

2. **Regression Protection**: Automated test coverage that captures current behavior, ensuring that the upcoming rename (Task 3) doesn't break existing functionality.

3. **Architecture Documentation**: Clear mapping of:
   - Where conversations are created (cursor-runner entry points)
   - How they're stored (Redis structure)
   - How they're retrieved (API endpoints)
   - How they're displayed (UI components)

4. **Test Infrastructure**: Baseline test suite that can be extended as new features are added, providing confidence for refactoring.

### Success Criteria
- All conversation creation/retrieval paths are traced and documented
- Visual baseline captured (screenshots or visual regression tests)
- Automated tests exist for all critical user flows
- Test coverage report shows baseline metrics
- Documentation updated with current architecture

## User Stories

### As a Developer
- **Story 1**: I want to understand how the current conversation system works so that I can safely refactor it without breaking existing functionality.
- **Story 2**: I want automated tests that verify current behavior so that I can confidently rename components without introducing regressions.

### As a QA Engineer
- **Story 3**: I want visual baselines of the current UI so that I can detect any unintended visual changes during refactoring.
- **Story 4**: I want test coverage metrics so that I know which areas are protected by automated tests.

### As a Product Owner
- **Story 5**: I want assurance that existing note-taking functionality will continue to work after the rename so that users aren't disrupted.

## Suggested Automated Tests

### Unit Tests
1. **API Client Tests** (`jarek-va-ui`):
   ```typescript
   describe('Conversations API Client', () => {
     it('fetches conversation list from /conversations/api/list', async () => {
       // Mock fetch, verify endpoint and response handling
     });
     it('fetches single conversation from /conversations/api/:id', async () => {
       // Test detail endpoint
     });
     it('handles network errors gracefully', async () => {
       // Test error handling
     });
   });
   ```

2. **Redis Storage Tests** (`cursor-runner`):
   ```typescript
   describe('Conversation Storage', () => {
     it('creates conversation with correct Redis key format', async () => {
       // Verify cursor:conversation:{id} format
     });
     it('retrieves conversation by ID', async () => {
       // Test retrieval logic
     });
     it('handles missing conversations', async () => {
       // Test error cases
     });
   });
   ```

### Integration Tests
3. **End-to-End Conversation Flow**:
   ```typescript
   describe('Conversation Flow', () => {
     it('creates conversation in cursor-runner and displays in UI', async () => {
       // Full flow: create → store → retrieve → display
     });
     it('updates conversation and reflects changes in UI', async () => {
       // Test update flow
     });
   });
   ```

4. **API Contract Tests**:
   ```typescript
   describe('API Contracts', () => {
     it('list endpoint returns expected structure', async () => {
       // Verify response schema
     });
     it('detail endpoint returns expected structure', async () => {
       // Verify response schema
     });
   });
   ```

### Visual Regression Tests
5. **UI Baseline Capture**:
   - Capture screenshots of:
     - Conversation list view
     - Conversation detail view
     - Empty states
     - Loading states
     - Error states
   - Store as baseline for visual regression testing

### Component Tests
6. **React Component Tests**:
   ```typescript
   describe('ConversationListView', () => {
     it('renders list of conversations', () => {
       // Test rendering with mock data
     });
     it('shows loading state', () => {
       // Test loading indicator
     });
     it('shows error state', () => {
       // Test error display
     });
   });
   ```

## Inherent Risks

### High Risk
1. **Incomplete Baseline**:
   - **Risk**: Missing critical flows in baseline documentation, leading to regressions during refactoring
   - **Mitigation**: Systematic tracing of all code paths, peer review of documentation, comprehensive test coverage

2. **Test Gaps**:
   - **Risk**: Critical user flows not covered by tests, allowing regressions to slip through
   - **Mitigation**: Code coverage analysis, review of test plans, manual testing checklist

### Medium Risk
3. **API Contract Changes**:
   - **Risk**: Unintended changes to API contracts during refactoring, breaking frontend
   - **Mitigation**: API contract tests, schema validation, versioning strategy

4. **Redis Key Structure Assumptions**:
   - **Risk**: Incorrect assumptions about Redis key structure, causing data loss or corruption
   - **Mitigation**: Document actual key patterns, add validation, test with real Redis instance

5. **Performance Regressions**:
   - **Risk**: Refactoring introduces performance issues not caught by functional tests
   - **Mitigation**: Performance benchmarks, load testing, monitoring

### Low Risk
6. **Documentation Drift**:
   - **Risk**: Documentation becomes outdated as code evolves
   - **Mitigation**: Keep docs close to code, review in PRs, automated doc generation where possible

7. **Test Maintenance Burden**:
   - **Risk**: Tests become brittle and require constant updates
   - **Mitigation**: Use stable selectors, mock external dependencies, maintain test utilities
